{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8123d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from pyqtorch.core.circuit import QuantumCircuit\n",
    "from pyqtorch.ansatz import AlternateLayerAnsatz\n",
    "from pyqtorch.embedding import SingleLayerEncoding\n",
    "from pyqtorch.core.operation import Z, RX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcefb02",
   "metadata": {},
   "source": [
    "# Generate a Hamiltonian from a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb071b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 3\n",
    "n_nodes = n_qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b210a98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# random\n",
    "\n",
    "# graph = nx.gnp_random_graph(n_nodes, 1., seed=42)\n",
    "\n",
    "# or custom one\n",
    "\n",
    "# graph = nx.Graph()\n",
    "# graph.add_edge(0, 1, weight=0.5)\n",
    "# graph.add_edge(1, 2, weight=0.1)\n",
    "# graph.add_node(0, weight=100.)\n",
    "# nx.draw(graph, with_labels=True)\n",
    "\n",
    "# generate a graph from a linear system\n",
    "\n",
    "A = np.array([[2,2,2],[2,2,2],[2,2,2]])\n",
    "b = np.array([3,3,3])\n",
    "\n",
    "def linear_system_to_graph(A, b):\n",
    "    graph = nx.Graph()\n",
    "    for idx, el in np.ndenumerate(b):\n",
    "        graph.add_node(idx[0], weight=el)\n",
    "    for idx, el in np.ndenumerate(A):\n",
    "        if el != 0.0:\n",
    "            graph.add_edge(idx[0], idx[1], weight=el)\n",
    "            graph.add_edge(idx[0], idx[1], weight=el)\n",
    "    return graph\n",
    "\n",
    "graph = linear_system_to_graph(A, b)\n",
    "nx.draw(graph, with_labels=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc2b35f2",
   "metadata": {},
   "source": [
    "Data(x=[2, 2], edge_index=[2, 3], edge_attr=[3], y=[2], A=[2, 2], X=[2], B=[2], norm_A=0.7036166653489919, norm_X=0.8782603873028308, norm_B=0.10631540677877555)\n",
    "----------- x: features -----------\n",
    "tensor([[1., 0.],\n",
    "        [0., 0.]])\n",
    "----------- edge_attr -----------\n",
    "tensor([0.8280, 0.1720, 0.1720])\n",
    "----------- edge_index -----------\n",
    "tensor([[0, 0],\n",
    "        [0, 1],\n",
    "        [1, 0]])\n",
    "----------- y: solution -----------\n",
    "tensor([0., 1.])\n",
    "----------- norm y -----------\n",
    "tensor(1.)\n",
    "----------- normalized a, x, b -----------\n",
    "tensor([[0.8280, 0.1720],\n",
    "        [0.1720, 0.0000]])\n",
    "tensor([0., 1.])\n",
    "tensor([1., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11158e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def torch_linear_system_to_graph(x, edge_index, edge_weights):\n",
    "    graph = nx.Graph()\n",
    "    for idx, el in np.ndenumerate(b):\n",
    "        graph.add_node(idx[0], weight=el)\n",
    "    for idx, el in np.ndenumerate(A):\n",
    "        if el != 0.0:\n",
    "            graph.add_edge(idx[0], idx[1], weight=el)\n",
    "            graph.add_edge(idx[0], idx[1], weight=el)\n",
    "    return graph\n",
    "\n",
    "graph = linear_system_to_graph(A, b)\n",
    "nx.draw(graph, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14c1c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "torch.Size([4])\n",
      "torch.Size([8])\n",
      "torch.Size([2, 2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# from pyqtorch.matrices import generate_ising_from_graph, sum_N\n",
    "from pyqtorch.matrices import ZZ, NN, single_N, single_Z\n",
    "\n",
    "def generate_hamiltonian_from_graph(graph,\n",
    "                              precomputed_zz=None,\n",
    "                              type_ising='Z',\n",
    "                              device='cpu',\n",
    "                              use_edge_weights=True,\n",
    "                              use_self_loops=False,\n",
    "                              use_node_weights=False,\n",
    "                             ):\n",
    "    \n",
    "    \"\"\" Given a nx graph, generate the corresponding Ising Hamiltonian in PyQ format. \"\"\"\n",
    "    \n",
    "    # get the number of nodes\n",
    "    N = graph.number_of_nodes()\n",
    "    \n",
    "    # construct the hamiltonian\n",
    "    H = torch.zeros(2**N, dtype=torch.cdouble).to(device)\n",
    "    \n",
    "    # edge weights \n",
    "    # go throught the edges and put the ZZ between correspoding nodes\n",
    "    for edge in graph.edges.data():\n",
    "        \n",
    "        # check that the types are integers, otherwise code will run but graph will be incorrect\n",
    "        assert type(edge[0]) == int\n",
    "        assert type(edge[1]) == int\n",
    "        \n",
    "        # initialize edge weights\n",
    "        edge_weight = torch.tensor(1, dtype=torch.cdouble)\n",
    "        if use_edge_weights:\n",
    "            if len(edge[2]) > 0:\n",
    "                edge_weight = torch.tensor(edge[2]['weight'],  dtype=torch.cdouble)\n",
    "        \n",
    "        # if you already have ZZ(N, edge[0], edge[1], device) computed\n",
    "        if precomputed_zz is not None:\n",
    "            if (edge[0], edge[1]) in precomputed_zz[N]:\n",
    "                key = (edge[0], edge[1])\n",
    "            else:\n",
    "                key = (edge[1], edge[0])\n",
    "            H += edge_weight * precomputed_zz[N][key]\n",
    "        else:\n",
    "            # define \n",
    "            if type_ising == 'Z':\n",
    "                if use_self_loops:\n",
    "                    H += edge_weight * ZZ(N, edge[0], edge[1], device)\n",
    "                elif edge[0] != edge[1]:\n",
    "                    H += edge_weight * ZZ(N, edge[0], edge[1], device)\n",
    "            elif type_ising == 'N':\n",
    "                if use_self_loops:\n",
    "                    H += edge_weight * NN(N, edge[0], edge[1], device)\n",
    "                elif edge[0] != edge[1]:\n",
    "                    H += edge_weight * NN(N, edge[0], edge[1], device)\n",
    "            else:\n",
    "                raise ValueError(\"'type_ising' must be in ['Z', 'N']\")\n",
    "    \n",
    "    # node weights\n",
    "    if use_node_weights:\n",
    "        for node in graph.nodes.data():\n",
    "            assert type(node[0]) == int\n",
    "            if len(node[1]) > 0:\n",
    "                node_weight = torch.tensor(node[1]['weight'],  dtype=torch.cdouble)\n",
    "                if type_ising == 'N':\n",
    "                    H += node_weight * single_N(N, node[0], device)\n",
    "                elif type_ising == 'Z':\n",
    "                    H += node_weight * single_Z(N, node[0], device)\n",
    "                else:\n",
    "                    raise ValueError(\"'type_ising' must be in ['Z', 'N']\")\n",
    "           \n",
    "    return H\n",
    "\n",
    "graph_hamiltonian_raw = generate_hamiltonian_from_graph(graph, type_ising='Z',\n",
    "                                                       use_edge_weights=True,\n",
    "                                                       use_self_loops=True,\n",
    "                                                       use_node_weights=True)\n",
    "print(graph_hamiltonian_raw.shape)\n",
    "graph_hamiltonian = graph_hamiltonian_raw.reshape([2] * n_nodes + [1])\n",
    "print(graph_hamiltonian.shape)\n",
    "graph_cost = graph_hamiltonian #1.2*ising_matrix - sum_N(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ace5dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21.+0.j,  7.+0.j,  7.+0.j,  1.+0.j,  7.+0.j,  1.+0.j,  1.+0.j,  3.+0.j],\n",
      "       dtype=torch.complex128)\n",
      "tensor([[[[21.+0.j],\n",
      "          [ 7.+0.j]],\n",
      "\n",
      "         [[ 7.+0.j],\n",
      "          [ 1.+0.j]]],\n",
      "\n",
      "\n",
      "        [[[ 7.+0.j],\n",
      "          [ 1.+0.j]],\n",
      "\n",
      "         [[ 1.+0.j],\n",
      "          [ 3.+0.j]]]], dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "print(graph_hamiltonian_raw) # these must be the diagonal elements\n",
    "print(graph_hamiltonian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4d7a80",
   "metadata": {},
   "source": [
    "# Define a model to run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c21ab048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIS(QuantumCircuit):\n",
    "    \"\"\" Construct the circuit of QAOA and compute the expectation value. \"\"\"\n",
    "    def __init__(self, n_qubits, n_layers):\n",
    "        super().__init__(n_qubits)\n",
    "        self.beta = nn.Parameter(torch.empty(n_layers,))\n",
    "        self.gamma = nn.Parameter(torch.empty(n_layers,))\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        init.uniform_(self.beta, -2 * np.pi, 2 * np.pi)\n",
    "        init.uniform_(self.gamma, -2 * np.pi, 2 * np.pi)\n",
    "        \n",
    "    def forward(self, return_cost=False):\n",
    "        state = self.uniform_state()\n",
    "        for b, g in zip(self.beta, self.gamma):\n",
    "            state = state * torch.exp(-1j * g * graph_hamiltonian)\n",
    "            for i in range(self.n_qubits):\n",
    "                state = RX(b, state, [i], self.n_qubits)\n",
    "        if return_cost:\n",
    "            return torch.real(torch.sum(torch.abs(state)**2 * graph_cost))\n",
    "        else:\n",
    "            state = state.reshape((2**self.n_qubits,))\n",
    "            return torch.abs(state)**2\n",
    "\n",
    "        \n",
    "class Model(QuantumCircuit):\n",
    "    \"\"\" Construct the circuit, embed the data x and compute the expectation value. \"\"\"\n",
    "    def __init__(self, n_qubits, n_layers, return_cost):\n",
    "        super().__init__(n_qubits)\n",
    "        self.ansatz1 = AlternateLayerAnsatz(n_qubits, n_layers) # hardware-efficient\n",
    "        self.embedding = SingleLayerEncoding(n_qubits)\n",
    "        self.ansatz2 = AlternateLayerAnsatz(n_qubits, n_layers)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.uniform_(self.beta, -2 * np.pi, 2 * np.pi)\n",
    "        init.uniform_(self.gamma, -2 * np.pi, 2 * np.pi)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = len(x)\n",
    "        state = self.init_state(batch_size)\n",
    "        state = self.ansatz1(state)\n",
    "        state = self.embedding(state, x)\n",
    "        state = self.ansatz2(state)\n",
    "        \n",
    "        if return_cost:\n",
    "            return torch.real(torch.sum(torch.abs(state)**2 * graph_cost))\n",
    "        else:\n",
    "            new_state = Z(state, [0], self.n_qubits)\n",
    "            state = state.reshape((2**self.n_qubits, batch_size))\n",
    "            new_state = new_state.reshape((2**self.n_qubits, batch_size))\n",
    "            return torch.real(torch.sum(torch.conj(state) * new_state, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c96a87c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphHamiltonianEncoding(QuantumCircuit):\n",
    "    def __init__(self, n_qubits, n_layers, graph_hamiltonian, parameters=None):\n",
    "        super().__init__(n_qubits)\n",
    "        self.gamma = nn.Parameter(torch.empty(n_layers,))\n",
    "        if parameters == None:\n",
    "            self.reset_parameters()\n",
    "        else:\n",
    "            self.gamma = parameters\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        init.uniform_(self.gamma, -2 * np.pi, 2 * np.pi)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        print(self.gamma)\n",
    "        for g in self.gamma:\n",
    "            state = state * torch.exp(-1j * g * graph_hamiltonian)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b92deb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 s  251 ns per loop (mean  std. dev. of 10 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10000 -r 10\n",
    "# won't update the result just time it \n",
    "n_layers = 1\n",
    "g = nn.Parameter(torch.tensor([0.3 for _ in range(n_layers)]))\n",
    "exp = torch.exp(-1j * g * graph_hamiltonian)\n",
    "# print(exp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4468842",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 1\n",
    "g = nn.Parameter(torch.tensor([0.5 for _ in range(n_layers)]))\n",
    "exp = torch.exp(-1j * g * graph_hamiltonian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbb493c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.4755+0.8797j],\n",
      "          [-0.9365+0.3508j]],\n",
      "\n",
      "         [[-0.9365+0.3508j],\n",
      "          [ 0.8776-0.4794j]]],\n",
      "\n",
      "\n",
      "        [[[-0.9365+0.3508j],\n",
      "          [ 0.8776-0.4794j]],\n",
      "\n",
      "         [[ 0.8776-0.4794j],\n",
      "          [ 0.0707-0.9975j]]]], dtype=torch.complex128, grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8f13f",
   "metadata": {},
   "source": [
    "Trying to make it to avoid reexponentiating, it is possible partly but won't allow for continuous evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8502376",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exponentiation(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        graph_hamiltonian,\n",
    "        parameters=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.graph_hamiltonian = graph_hamiltonian\n",
    "        if parameters is None:\n",
    "            self.g = nn.Parameter(torch.tensor([1.1 for _ in range(n_layers)]))\n",
    "        else:\n",
    "            self.g = parameters\n",
    "\n",
    "    def forward(self):\n",
    "        return torch.exp(-1j * self.g * self.graph_hamiltonian)\n",
    "\n",
    "g = nn.Parameter(torch.tensor([10. for _ in range(n_layers)]))\n",
    "# print(g)\n",
    "exp = Exponentiation(graph_hamiltonian, parameters=g)\n",
    "# print(eval_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1bee5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.6 s  358 ns per loop (mean  std. dev. of 10 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10000 -r 10\n",
    "eval_exp = exp.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0c01ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_exp = exp.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db1933bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.8839-0.4677j],\n",
      "          [ 0.6333-0.7739j]],\n",
      "\n",
      "         [[ 0.6333-0.7739j],\n",
      "          [-0.8391+0.5440j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6333-0.7739j],\n",
      "          [-0.8391+0.5440j]],\n",
      "\n",
      "         [[-0.8391+0.5440j],\n",
      "          [ 0.1543+0.9880j]]]], dtype=torch.complex128, grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(eval_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51b97571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nn_parameters(list_parameters, flow):\n",
    "    # change all parameters\n",
    "    state_dict = flow.state_dict()\n",
    "    count = 0\n",
    "    for name, param in state_dict.items():\n",
    "#         print(name, param)\n",
    "        # Transform the parameter as required.\n",
    "        transformed_param = torch.tensor(list_parameters[count])\n",
    "        # Update the parameter.\n",
    "        param.copy_(transformed_param)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cd4361e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.35 s  110 ns per loop (mean  std. dev. of 10 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10000 -r 10\n",
    "set_nn_parameters([1.1], exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bec57cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_nn_parameters([10.1], exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d420f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.8839-0.4677j],\n",
      "          [ 0.6333-0.7739j]],\n",
      "\n",
      "         [[ 0.6333-0.7739j],\n",
      "          [-0.8391+0.5440j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6333-0.7739j],\n",
      "          [-0.8391+0.5440j]],\n",
      "\n",
      "         [[-0.8391+0.5440j],\n",
      "          [ 0.1543+0.9880j]]]], dtype=torch.complex128, grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(eval_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4028c6a",
   "metadata": {},
   "source": [
    "#### NOTE: You cannot modify the data just by resetting the parameters (you should trigger forward)\n",
    "#### So what you try above does NOT work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a86c98",
   "metadata": {},
   "source": [
    "Encode the the graph into a Hamiltonian and embed in a quantum state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74142184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1000], requires_grad=True)\n",
      "tensor([[[[0.3536+0.j],\n",
      "          [0.3536+0.j]],\n",
      "\n",
      "         [[0.3536+0.j],\n",
      "          [0.3536+0.j]]],\n",
      "\n",
      "\n",
      "        [[[0.3536+0.j],\n",
      "          [0.3536+0.j]],\n",
      "\n",
      "         [[0.3536+0.j],\n",
      "          [0.3536+0.j]]]], dtype=torch.complex128)\n",
      "Parameter containing:\n",
      "tensor([0.1000], requires_grad=True)\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_layers = 1\n",
    "parameters = nn.Parameter(torch.tensor([0.1 for _ in range(n_layers)]))\n",
    "# print(parameters)\n",
    "# parameters = nn.Parameter(torch.reshape(parameters, (n_layers,)))\n",
    "print(parameters)\n",
    "# parameters = None\n",
    "model = GraphHamiltonianEncoding(n_qubits, n_layers=n_layers, graph_hamiltonian=graph_hamiltonian, parameters=parameters)\n",
    "qc = QuantumCircuit(n_qubits)\n",
    "state = qc.uniform_state()\n",
    "print(state)\n",
    "state = model(state)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08600a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(QuantumCircuit):\n",
    "    \"\"\" Construct the circuit, embed the data x and compute the expectation value. \"\"\"\n",
    "    def __init__(self, n_qubits, n_layers, return_cost):\n",
    "        super().__init__(n_qubits)\n",
    "        self.ansatz1 = AlternateLayerAnsatz(n_qubits, n_layers) # hardware-efficient\n",
    "        self.embedding = SingleLayerEncoding(n_qubits)\n",
    "        self.ansatz2 = AlternateLayerAnsatz(n_qubits, n_layers)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.uniform_(self.beta, -2 * np.pi, 2 * np.pi)\n",
    "        init.uniform_(self.gamma, -2 * np.pi, 2 * np.pi)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        batch_size = len(x)\n",
    "        state = self.init_state(batch_size)\n",
    "        state = self.ansatz1(state)\n",
    "        state = self.embedding(state, x)\n",
    "        state = self.ansatz2(state)\n",
    "        if return_cost:\n",
    "            return torch.real(torch.sum(torch.abs(state)**2 * graph_cost))\n",
    "        else:\n",
    "            new_state = Z(state, [0], self.n_qubits)\n",
    "            state = state.reshape((2**self.n_qubits, batch_size))\n",
    "            new_state = new_state.reshape((2**self.n_qubits, batch_size))\n",
    "            return torch.real(torch.sum(torch.conj(state) * new_state, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f991438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 1 | Loss 3.5156372576025503\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 2 | Loss 11.8831857499901\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 3 | Loss 4.586997122278637\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 4 | Loss 4.824949383137246\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 5 | Loss 4.600556370068455\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 6 | Loss 3.3382424773697155\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 7 | Loss 2.8875225809679663\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 8 | Loss 3.4265839292417093\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 9 | Loss 1.9747469389459484\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 10 | Loss 1.1915110486341465\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 11 | Loss 1.7529103419818723\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 12 | Loss 2.127982309908409\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 13 | Loss 2.1272077648523866\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 14 | Loss 2.0273390657828956\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 15 | Loss 1.8667900250768457\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 16 | Loss 1.7059227421615883\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 17 | Loss 1.6545894064147477\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 18 | Loss 1.5615020673687852\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 19 | Loss 1.3619731319097066\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 20 | Loss 1.237162721577418\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 21 | Loss 1.2422807053844946\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 22 | Loss 1.2697919953234655\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 23 | Loss 1.3141516471763406\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 24 | Loss 1.385347501967574\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 25 | Loss 1.378599352303337\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 26 | Loss 1.2512181113763876\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 27 | Loss 1.1130708337357351\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 28 | Loss 1.0651950329685982\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 29 | Loss 1.0843268447021404\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 30 | Loss 1.1217860495289198\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 31 | Loss 1.1709644553620926\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 32 | Loss 1.1958774753209633\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 33 | Loss 1.1656955311473554\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 34 | Loss 1.1156689169437852\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 35 | Loss 1.0767542407711552\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 36 | Loss 1.0512357407272719\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 37 | Loss 1.0420885551945056\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 38 | Loss 1.0440024085120423\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 39 | Loss 1.046035041956499\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 40 | Loss 1.0433603509745195\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 41 | Loss 1.0437358777048211\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 42 | Loss 1.049664941657776\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 43 | Loss 1.0493826356171663\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 44 | Loss 1.0443316279705432\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 45 | Loss 1.0388998642293654\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 46 | Loss 1.0278822504122977\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 47 | Loss 1.0192198890778281\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 48 | Loss 1.0163315371576584\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 49 | Loss 1.014841194798474\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 50 | Loss 1.0178264704648614\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 51 | Loss 1.0202254449912262\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 52 | Loss 1.0175086733296272\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 53 | Loss 1.013924525282769\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 54 | Loss 1.0106584076169343\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 55 | Loss 1.0076680162693368\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 56 | Loss 1.0074019371234835\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 57 | Loss 1.0107332704820766\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 58 | Loss 1.0128746006192852\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 59 | Loss 1.0119737926528525\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 60 | Loss 1.0089942791252344\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 61 | Loss 1.0037126394622797\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 62 | Loss 1.0007122135297726\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 63 | Loss 1.001216756497155\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 64 | Loss 1.0029267662124415\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 65 | Loss 1.0054339386329483\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 66 | Loss 1.0065220563870785\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 67 | Loss 1.0056407976714032\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 68 | Loss 1.0037342249482153\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 69 | Loss 1.001742901888701\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 70 | Loss 1.0008523754028773\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 71 | Loss 1.0014163195726429\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 72 | Loss 1.0021715123291097\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 73 | Loss 1.0024033667774421\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 74 | Loss 1.0022021006914545\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 75 | Loss 1.001278888737702\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 76 | Loss 1.0007253448786302\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 77 | Loss 1.0006156004654212\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 78 | Loss 1.0008849382550467\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 79 | Loss 1.00141630450701\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 80 | Loss 1.001481212469106\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 81 | Loss 1.0011871014992735\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 82 | Loss 1.0007162462009442\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 83 | Loss 1.0002979121266762\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 84 | Loss 1.0001691921177913\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 85 | Loss 1.0002899483385872\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 86 | Loss 1.000454134861796\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 87 | Loss 1.0006319975762894\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 88 | Loss 1.000566943426372\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 89 | Loss 1.00044230143416\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 90 | Loss 1.0003107124147195\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 91 | Loss 1.0002143172651614\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 92 | Loss 1.0002116974098405\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 93 | Loss 1.0001978470210566\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 94 | Loss 1.0002167965916924\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 95 | Loss 1.0002048978017881\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 96 | Loss 1.000162223984244\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 97 | Loss 1.0001348891400745\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 98 | Loss 1.0001145246224192\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 99 | Loss 1.0001176359634283\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 100 | Loss 1.0001330196893008\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 101 | Loss 1.0001311647415716\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 102 | Loss 1.0001322276702358\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 103 | Loss 1.0000879873840476\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 104 | Loss 1.0000522292349434\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 105 | Loss 1.000025346483593\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 106 | Loss 1.000029336722368\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 107 | Loss 1.0000524898337217\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 108 | Loss 1.0000714389010916\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 109 | Loss 1.000076532969407\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 110 | Loss 1.000056125900206\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 111 | Loss 1.0000280772523726\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 112 | Loss 1.0000157035835555\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 113 | Loss 1.0000153869277926\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 114 | Loss 1.0000286795306255\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 115 | Loss 1.0000319422485244\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 116 | Loss 1.0000294780572487\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 117 | Loss 1.0000166527543823\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 118 | Loss 1.0000085144376414\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 119 | Loss 1.0000111837269898\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 120 | Loss 1.000018973992098\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 121 | Loss 1.000023707381375\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 122 | Loss 1.0000170380487203\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 123 | Loss 1.0000088957230622\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 124 | Loss 1.0000008261849285\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 125 | Loss 1.00000186663217\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 126 | Loss 1.0000072330829535\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 127 | Loss 1.0000102597688914\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 128 | Loss 1.0000108156386336\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 129 | Loss 1.000007669590254\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 130 | Loss 1.0000036812421187\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 131 | Loss 1.0000023640366464\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 132 | Loss 1.0000035752072365\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 133 | Loss 1.0000046580776496\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 134 | Loss 1.0000040846017186\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 135 | Loss 1.0000027826940108\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 136 | Loss 1.0000022170134253\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 137 | Loss 1.0000016203756072\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 138 | Loss 1.0000020447200464\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 139 | Loss 1.0000030007785798\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 140 | Loss 1.000003235588786\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 141 | Loss 1.0000005515446058\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 142 | Loss 1.0000017602329034\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 143 | Loss 0.9999999410309031\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 144 | Loss 1.0000003101860884\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 145 | Loss 1.0000003774713555\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 146 | Loss 1.0000020068151223\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 147 | Loss 1.0000012353209002\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 148 | Loss 1.000000284795163\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 149 | Loss 1.0000005906978002\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 150 | Loss 1.0000002354593476\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 151 | Loss 1.000000301702587\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 152 | Loss 1.0000000608304624\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 153 | Loss 0.9999995090007114\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 154 | Loss 0.9999993670004935\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 155 | Loss 1.0000003390852292\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 156 | Loss 1.0000006371537968\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 157 | Loss 1.0000000144339674\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 158 | Loss 1.0000003389675736\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 159 | Loss 1.0000010863687232\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 160 | Loss 0.9999998767170256\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 161 | Loss 0.999999271221848\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 162 | Loss 0.9999996763292172\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 163 | Loss 0.9999996552988082\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 164 | Loss 0.9999999967265731\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 165 | Loss 1.000000260553725\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 166 | Loss 0.9999997300356989\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 167 | Loss 1.0000001015906632\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 168 | Loss 1.0000006736105889\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 169 | Loss 1.000000718506065\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 170 | Loss 0.9999999139684685\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 171 | Loss 0.9999992126438535\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 172 | Loss 0.9999992819668562\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 173 | Loss 1.0000000622535876\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 174 | Loss 0.9999996299252676\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 175 | Loss 0.999999554287209\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 176 | Loss 1.000000006514854\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 177 | Loss 1.0000001983503255\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 178 | Loss 0.9999989760260453\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 179 | Loss 0.9999999152955923\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 180 | Loss 1.0000002746138745\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 181 | Loss 1.0000002089433833\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 182 | Loss 1.0000004125848303\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 183 | Loss 0.9999994204510969\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 184 | Loss 0.9999999227830572\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 185 | Loss 0.9999994971692237\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 186 | Loss 0.9999990531150085\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 187 | Loss 0.9999999000478724\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 188 | Loss 0.9999992154994275\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 189 | Loss 0.9999996634404561\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 190 | Loss 0.999999937316097\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 191 | Loss 0.9999996676953099\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 192 | Loss 1.0000001704120443\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 193 | Loss 1.0000003806164863\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 194 | Loss 1.000000055774605\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 195 | Loss 0.9999997541734884\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 196 | Loss 1.0000001784497052\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 197 | Loss 1.000000194957423\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 198 | Loss 1.0000003010112455\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 199 | Loss 0.9999995676047831\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 200 | Loss 0.9999993043122076\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 201 | Loss 1.0000004148828\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 202 | Loss 1.0000000824676274\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 203 | Loss 1.0000001673369434\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 204 | Loss 0.999999521520885\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 205 | Loss 0.9999995090936655\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 206 | Loss 1.0000002301023274\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 207 | Loss 0.9999997312118258\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 208 | Loss 0.9999999333516183\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 209 | Loss 1.0000001493121387\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 210 | Loss 0.9999991937926674\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 211 | Loss 0.9999992841761911\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 212 | Loss 0.9999992465409202\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 213 | Loss 0.9999999540906841\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 214 | Loss 0.9999994232858826\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 215 | Loss 1.0000001628007515\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 216 | Loss 1.0000003496481167\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 217 | Loss 1.0000002368742034\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 218 | Loss 1.0000001325042163\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 219 | Loss 0.9999998853944134\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 220 | Loss 0.9999992890892715\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 221 | Loss 1.0000002001234376\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 222 | Loss 0.9999999580329934\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 223 | Loss 0.9999996345791724\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 224 | Loss 0.9999998950983824\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 225 | Loss 0.9999998389798959\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 226 | Loss 0.9999998159488768\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 227 | Loss 0.999999960783239\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 228 | Loss 1.0000000145138521\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 229 | Loss 1.0000005650352328\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 230 | Loss 0.9999999692303339\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 231 | Loss 0.999999341686177\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 232 | Loss 0.9999997026761066\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 233 | Loss 0.9999990195778363\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 234 | Loss 0.9999987729037811\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 235 | Loss 0.9999992762321752\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 236 | Loss 1.0000000667454616\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 237 | Loss 1.0000003128134198\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 238 | Loss 1.0000003337030297\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 239 | Loss 0.999999182377954\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 240 | Loss 0.9999991541429554\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 241 | Loss 1.0000000658639134\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 242 | Loss 0.999999477619103\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 243 | Loss 0.9999986190876566\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 244 | Loss 0.9999997977381496\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 245 | Loss 0.9999992710886505\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 246 | Loss 1.0000001896269617\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 247 | Loss 0.9999999234400341\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 248 | Loss 1.000000180879038\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 249 | Loss 0.9999996981270742\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 250 | Loss 0.9999999054685863\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 251 | Loss 0.9999993114775851\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 252 | Loss 0.9999994633818363\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 253 | Loss 0.9999998245989494\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 254 | Loss 0.9999991816624096\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 255 | Loss 1.0000003306364558\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 256 | Loss 0.9999992109325604\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 257 | Loss 0.9999995216893826\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 258 | Loss 1.0000000190234695\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 259 | Loss 0.9999998837976474\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 260 | Loss 0.9999998431527088\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 261 | Loss 1.000000472602827\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 262 | Loss 0.9999995434691329\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 263 | Loss 0.9999996160512125\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 264 | Loss 0.99999986310146\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 265 | Loss 0.9999995313148451\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 266 | Loss 0.9999994103227694\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 267 | Loss 0.9999997245072554\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 268 | Loss 0.9999994543579684\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 269 | Loss 0.999999419870951\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 270 | Loss 1.0000000835266127\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 271 | Loss 0.9999995708030986\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 272 | Loss 0.999999555804643\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 273 | Loss 1.0000000686986898\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 274 | Loss 0.9999997727406865\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 275 | Loss 0.9999997463436042\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 276 | Loss 0.9999995696488038\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 277 | Loss 0.9999994533945424\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 278 | Loss 0.9999994390758076\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 279 | Loss 1.000000024624136\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 280 | Loss 0.9999991868233613\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 281 | Loss 0.9999992425979862\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 282 | Loss 0.99999958026801\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 283 | Loss 0.9999994150412048\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 284 | Loss 0.9999991527784079\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 285 | Loss 0.9999992182304638\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 286 | Loss 1.000000122421913\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 287 | Loss 1.0000003691050956\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 288 | Loss 0.9999995654035453\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 289 | Loss 1.0000006975617133\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 290 | Loss 0.9999993928138446\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 291 | Loss 0.9999995557250607\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 292 | Loss 0.9999992303524641\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 293 | Loss 1.0000009257732194\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 294 | Loss 0.999999881502469\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 295 | Loss 0.9999997895162706\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 296 | Loss 0.9999995685633513\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 297 | Loss 1.0000002674109214\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 298 | Loss 0.9999996277810104\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 299 | Loss 1.0000000766774875\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 300 | Loss 1.0000009534925929\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 301 | Loss 0.9999997342259473\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 302 | Loss 1.0000008918734007\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 303 | Loss 1.000000755876397\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 304 | Loss 0.9999993174682156\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 305 | Loss 1.000000926663314\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 306 | Loss 0.9999989872247439\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 307 | Loss 1.0000002915240234\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 308 | Loss 1.0000000748626037\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 309 | Loss 0.9999991090408804\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 310 | Loss 1.0000006210644932\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 311 | Loss 0.9999988979261341\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 312 | Loss 1.000000646925337\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 313 | Loss 1.0000006609921233\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 314 | Loss 0.9999998941576442\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 315 | Loss 1.0000000214724853\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 316 | Loss 1.0000000077871114\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 317 | Loss 0.9999997130057595\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 318 | Loss 0.999999797341137\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 319 | Loss 0.9999992082703055\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 320 | Loss 0.9999998875244445\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 321 | Loss 0.9999996745819204\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 322 | Loss 0.9999990080504946\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 323 | Loss 0.9999999416279752\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 324 | Loss 0.999998673994536\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 325 | Loss 1.000001085659993\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 326 | Loss 0.9999999507155167\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 327 | Loss 0.99999978901821\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 328 | Loss 1.0000003859584927\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 329 | Loss 0.9999998827045224\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 330 | Loss 1.000000198292263\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 331 | Loss 0.999999756990926\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 332 | Loss 1.0000005239748935\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 333 | Loss 1.0000000327968654\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 334 | Loss 0.9999996489911034\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 335 | Loss 1.0000000053276001\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 336 | Loss 0.9999997808802452\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 337 | Loss 0.9999998132384893\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 338 | Loss 0.9999997114367543\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 339 | Loss 0.9999996920614291\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 340 | Loss 0.9999996097262109\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 341 | Loss 1.0000001029345946\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 342 | Loss 0.9999998862086183\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 343 | Loss 0.999999912450841\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 344 | Loss 0.9999999218029667\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 345 | Loss 1.0000000629261985\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 346 | Loss 1.0000000738806467\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 347 | Loss 0.9999995175487026\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 348 | Loss 0.9999997093242788\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 349 | Loss 0.9999999655871621\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 350 | Loss 0.9999996863509204\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 351 | Loss 0.9999993635671698\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 352 | Loss 0.999999463019275\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 353 | Loss 0.9999997620796595\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 354 | Loss 1.000000217605065\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 355 | Loss 0.9999996783476168\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 356 | Loss 0.9999995709022342\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 357 | Loss 0.9999995162888369\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 358 | Loss 1.0000000867500587\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 359 | Loss 1.0000001709867066\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 360 | Loss 0.9999994116527826\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 361 | Loss 0.9999998066450234\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 362 | Loss 0.9999995743306977\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 363 | Loss 0.9999995228628278\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 364 | Loss 0.9999993308195334\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 365 | Loss 0.9999998720278087\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 366 | Loss 0.9999992416586176\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 367 | Loss 1.0000000965623679\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 368 | Loss 1.000000050235316\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 369 | Loss 1.0000011395880999\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 370 | Loss 0.9999998073538898\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 371 | Loss 1.0000005926887219\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 372 | Loss 0.9999996340497102\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 373 | Loss 0.9999997884903982\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 374 | Loss 1.0000000409478607\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 375 | Loss 0.9999994576227786\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 376 | Loss 0.9999998157797244\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 377 | Loss 1.0000003238312998\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 378 | Loss 0.99999982528867\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 379 | Loss 1.0000008145213402\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 380 | Loss 0.9999998824539325\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 381 | Loss 1.0000012867587609\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 382 | Loss 1.0000013723879069\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 383 | Loss 1.000000850587813\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 384 | Loss 1.0000022448920298\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 385 | Loss 1.0000045903676635\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 386 | Loss 1.000006014856078\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 387 | Loss 1.0000113563893813\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 388 | Loss 1.0000199608783182\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 389 | Loss 1.0000366314670102\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 390 | Loss 1.000067015391659\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 391 | Loss 1.0001205075245463\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 392 | Loss 1.000224883658851\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 393 | Loss 1.000425212188207\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 394 | Loss 1.0008186184396992\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 395 | Loss 1.0015990168675768\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 396 | Loss 1.003167992368971\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 397 | Loss 1.0063490982765229\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 398 | Loss 1.01279137524736\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 399 | Loss 1.025662161978719\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 400 | Loss 1.0502121541507932\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 401 | Loss 1.092352783881033\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 402 | Loss 1.1485747471792238\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 403 | Loss 1.1872483200147221\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 404 | Loss 1.1529556420254365\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 405 | Loss 1.0565842523440616\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 406 | Loss 1.0006561515320223\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 407 | Loss 1.0371219447037507\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 408 | Loss 1.0829130163480438\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 409 | Loss 1.0539368844236432\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 410 | Loss 1.005427687741814\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 411 | Loss 1.017845812392062\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 412 | Loss 1.0462473175523055\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 413 | Loss 1.0283787494362775\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 414 | Loss 1.0041294406993593\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 415 | Loss 1.0160658200342976\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 416 | Loss 1.0284951350440605\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 417 | Loss 1.0132893228424675\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 418 | Loss 1.002477541018514\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 419 | Loss 1.014485407215278\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 420 | Loss 1.0177815878641105\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 421 | Loss 1.0035113505019522\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 422 | Loss 1.0035390225128953\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 423 | Loss 1.01398039195672\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 424 | Loss 1.0074854998832745\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 425 | Loss 1.0001007796460153\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 426 | Loss 1.0073322752055005\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 427 | Loss 1.0085399865944227\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 428 | Loss 1.0013320559194354\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 429 | Loss 1.002402587306174\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 430 | Loss 1.00653671192286\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 431 | Loss 1.0033169796470869\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 432 | Loss 1.0003781674942747\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 433 | Loss 1.003543348505442\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 434 | Loss 1.0040879860871756\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 435 | Loss 1.0004554915964645\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 436 | Loss 1.0012267861760158\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 437 | Loss 1.003393967206577\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 438 | Loss 1.0012313779432938\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 439 | Loss 1.0002083272256348\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 440 | Loss 1.0019999510479183\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 441 | Loss 1.0017052743961887\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 442 | Loss 1.0002212052993218\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 443 | Loss 1.0007394252207247\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 444 | Loss 1.00153264776438\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 445 | Loss 1.0006257244661507\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 446 | Loss 1.0000952126151803\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 447 | Loss 1.0009414006446766\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 448 | Loss 1.000884984929693\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 449 | Loss 1.000049142930205\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 450 | Loss 1.0003520031895499\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 451 | Loss 1.000782013628456\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 452 | Loss 1.0002736440282005\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 453 | Loss 1.0000604809226787\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 454 | Loss 1.0004402631454379\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 455 | Loss 1.00042548891915\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 456 | Loss 1.0000763918715683\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 457 | Loss 1.000124303058413\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 458 | Loss 1.0003618314440392\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 459 | Loss 1.0002027671591571\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 460 | Loss 1.000003840335177\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 461 | Loss 1.0001739122479443\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 462 | Loss 1.000247499023632\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 463 | Loss 1.0000523037985343\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 464 | Loss 1.0000329214982102\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 465 | Loss 1.0001641307707336\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 466 | Loss 1.0001255773869802\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 467 | Loss 1.0000174584362909\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 468 | Loss 1.000047770491638\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 469 | Loss 1.0001158676493607\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 470 | Loss 1.0000677344066018\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 471 | Loss 1.0000031879413707\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 472 | Loss 1.0000480237186522\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 473 | Loss 1.0000838924151\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 474 | Loss 1.0000273764761354\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 475 | Loss 1.0000032669086307\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 476 | Loss 1.000044881647502\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 477 | Loss 1.000049885419796\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 478 | Loss 1.000012311015257\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 479 | Loss 1.0000072455112994\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 480 | Loss 1.000032304789542\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 481 | Loss 1.0000307677835645\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 482 | Loss 1.0000072852229005\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 483 | Loss 1.0000047131151732\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 484 | Loss 1.0000233047345153\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 485 | Loss 1.0000206326486532\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 486 | Loss 1.0000026991857425\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 487 | Loss 1.000003999039272\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 488 | Loss 1.0000162764873504\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 489 | Loss 1.0000126084754415\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 490 | Loss 1.0000018063664535\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 491 | Loss 1.0000032072337137\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 492 | Loss 1.0000095264895505\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 493 | Loss 1.0000091827776596\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 494 | Loss 1.000001819082242\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 495 | Loss 1.000000433314389\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 496 | Loss 1.0000067435514675\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 497 | Loss 1.000006490267106\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 498 | Loss 1.0000008455274578\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 499 | Loss 1.0000007952271883\n",
      "torch.Size([2, 2, 2, 1])\n",
      "tensor([[[[-0.1785-0.3052j],\n",
      "          [ 0.2704-0.2278j]],\n",
      "\n",
      "         [[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2704-0.2278j],\n",
      "          [ 0.3518-0.0353j]],\n",
      "\n",
      "         [[ 0.3518-0.0353j],\n",
      "          [ 0.3378-0.1045j]]]], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "Epoch 500 | Loss 1.0000038461822556\n"
     ]
    }
   ],
   "source": [
    "model = MIS(n_nodes, 20)\n",
    "# model = Model(n_nodes, 20, return_cost=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.02)\n",
    "epochs = 500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss = model(True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(state.shape)\n",
    "    print(state)\n",
    "    print(f\"Epoch {epoch+1} | Loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c6a7256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1166e-07, 1.3728e-10, 1.3728e-10, 3.3333e-01, 1.3728e-10, 3.3333e-01,\n",
      "        3.3333e-01, 3.4452e-08], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'11'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = model()\n",
    "print(prob)\n",
    "mis = torch.argmax(prob)\n",
    "print(mis.item())\n",
    "# print(format(mis, '010b'))\n",
    "\"{0:b}\".format(mis.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddead15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('qugram')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4fba1bd487736e99db9fa6cac304ab42b086d6841ec6a317a1275c4a1deb14e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
